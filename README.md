# Machine Learning Final Project: Lung Cancer Survival Prediction

This is the final project of our Machine Learning bootcamp, where we demonstrate the skills and knowledge acquired throughout our studies. We have developed an end-to-end solution to predict survival months in lung cancer patients, integrating clinical data with socioeconomic determinants.

> *"Hard work always beats talent when talent doesn't work hard"* - Tim Notke

## ğŸ‘¥ Credits

**Team Members:**
> - [Betania Medina](https://github.com/Betaniammc)
> - [Carlos Restrepo](https://github.com/carlos-villa-restrepo) 
> - [Elius Trujillo](https://github.com/elius123ef)

**Academy:** > - [4Geeks Academy](https://4geeksacademy.com/us/index) 
> - **Bootcamp:** Spain-DS-20 
> - **Mentor:** [Ing. HÃ©ctor Chocobar TorrejÃ³n](https://github.com/hchocobar/)
> - **Teacher Assitant:** [Beatriz Solana Ros](https://github.com/mezcolantriz)

## ğŸ¯ Project Goal

The goal of this project is to develop a complete Machine Learning solution to:
- Process and clean complex oncological datasets (SEER).
- Perform a deep Exploratory Data Analysis (EDA) to find correlations between income and survival.
- Train and optimize a Gradient Boosting model (XGBoost) to predict survival time.
- Provide a tool for clinical and social insight through ML techniques.

## ğŸš€ Project Overview

### Problem Statement
Lung cancer prognosis is typically driven by clinical stages, but socioeconomic factors often play a hidden role in treatment access and outcomes. We aimed to build a model that quantifies how variables like **Income Level** and **Surgical History** impact a patient's life expectancy in months.

### Dataset
We utilized the **SEER (Surveillance, Epidemiology, and End Results)** dataset, focusing on Lung and Bronchus cancer cases (1975-2021).
- **Instances:** 60,000+ records.
- **Predictors:** 20+ variables including Stage, Age, Sex, Surgery History, and Median Household Income.

### Methodology
We implemented a regression pipeline comparing **Random Forest** and **XGBoost**. The process included Feature Engineering to consolidate cancer stages and cleaning categorical socioeconomic data to handle non-linear relationships.

### Results
The final **XGBoost** model achieved:
- **MAE (Mean Absolute Error):** 16.27 months.
- **RÂ² Score:** 0.30.
- **Key Insight:** Surgical intervention and income level are top predictors, showing a survival gap of over 50 months between the most and least favorable scenarios.

## ğŸ“ Project Phases

### Step 1: Problem Definition
The project addresses the need for personalized prognosis. We transformed raw clinical records into a supervised regression problem where the target is `Survival months`.

### Step 2: Acquiring and Loading
Data was sourced from the SEER database, processed into a structured format, and loaded using Pandas for initial cleaning.

### Step 3: Store the Information
The processed data was handled through a structured pipeline. We utilized SQL-based logic to filter relevant oncological events and ensure data integrity before the EDA phase.

### Step 4: Descriptive Analysis
We analyzed the distribution of survival times, finding a significant skew towards shorter durations in advanced stages. Statistical measures confirmed that 'Income Level' follows a multimodal distribution across different geographic regions in the dataset.

### Step 5: Full EDA
We performed a comprehensive EDA, identifying that:
- **Surgery** is a critical "pivot" variable.
- **Income** correlates with earlier detection (Localized stage).
- We split the data into **80% training** and **20% testing** sets.

### Step 6: Build the Model and Optimize It
We optimized an **XGBoost Regressor** using hyperparameter tuning. By refining `learning_rate` and `max_depth`, we improved the initial Random Forest baseline by reducing the MAE from 17.97 to 16.27 months.

### Step 7: Deploy the Model
*The model is prepared for deployment as a web service where users can input patient profiles to receive a survival estimation.*

## ğŸ“ Project Structure

ml-project-repo/

â”œâ”€â”€ ğŸ“ data/

â”‚ â”œâ”€â”€ ğŸ“ interim/ # Intermediate transformed data 

â”‚ â”œâ”€â”€ ğŸ“ processed/ # Final data used for modeling

â”‚ â””â”€â”€ ğŸ“ raw/ # Raw data without processing 

â”œâ”€â”€ ğŸ“ database/ # SQL scripts and database configs 

â”œâ”€â”€ ğŸ“ docs/

â”‚ â”œâ”€â”€ ğŸ“ Figures/ # Feature Importance and Scenario plots 

â”‚ â”œâ”€â”€ Dic.md # Data dictionary 

â”‚ â””â”€â”€ Reporte final EDA.md # Final clinical findings report 

â”œâ”€â”€ ğŸ“ models/

â”‚ â””â”€â”€ survival_xgboost_final.pkl # Trained XGBoost model

â”œâ”€â”€ ğŸ“ notebooks/

â”‚ â”œâ”€â”€ 01_eda_elius.ipynb # Phase 1: Exploratory Data Analysis

â”‚ â””â”€â”€ 02_ML_elius.ipynb # Phase 2: Machine Learning Modeling 

â”œâ”€â”€ ğŸ“ src/

â”‚ â””â”€â”€ predict_survival.py # Prediction engine script 

â”œâ”€â”€ ğŸ“ webapp/ # Deployment application (Streamlit/Flask)  


## ğŸ› ï¸ Technologies Used
- **Python:** Primary language.
- **Pandas & Numpy:** Data manipulation.
- **XGBoost & Scikit-Learn:** Machine Learning modeling.
- **Matplotlib & Seaborn:** Data visualization.
- **Joblib:** Model serialization.

## ğŸ“Š Results Summary
The analysis of scenarios demonstrated the model's consistency:
- **Ideal Scenario:** ~67.64 months (Localized + Surgery + High Income).
- **Critical Scenario:** ~14.76 months (Distant + No Surgery + Low Income).

## ğŸŒ Live Demo
*[Link to be added upon deployment]*